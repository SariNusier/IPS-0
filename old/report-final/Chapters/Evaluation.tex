\chapter{Results/Evaluation}
In this chapter we will review the performance of the resulting system and compare it with the requirements set in Chapter 3.
\section{IPS Performance Analysis}

The Java module implementing the Machine Learning algorithms uses only two types of classifiers, Naive Bayes and Bayes Network. Other classifiers were tested using the Weka GUI Explorer ~\cite{Weka}. 

Data was collected for two different buildings. The first set of data was taken in my personal flat. The surface area is approximately $55 m^2$ with all the rooms being close to each other. The rooms classified are: Kitchen, Bedroom, Living Room and Hallway. One assumption made was that, if the algorithm performed well in such a restricted environment, where the distance between rooms is quite limited, a better performance will be noticed in a larger space. The second set of data was taken at the Strand campus of King's College London. Because there was limited access to rooms and because of some people staring at a crazy looking guy walking around in circles talking to himself and lifting his phone in the air as if he was trying to film a concert or catch better signal, only a limited number of rooms were chosen for the test. After collecting the data, the classifiers were built and applied to the learning set. In order to get a more realistic result, the classifiers were also built with a part of the data, the rest being used as a test set.

In the flat tests, the four rooms mentioned above were taken into account. 87 measurements were taken: 19 for room a, 24 for room b, 25 for room c and 19 for room d. Applying the built classifier to the learning set yielded the following results:

\noindent Naive Bayes:
\begin{lstlisting}
Time taken to build model: 0 seconds
=== Evaluation on training set ===
=== Summary ===
Correctly Classified Instances          87              100      %
Incorrectly Classified Instances         0                0      %
Total Number of Instances               87     
=== Confusion Matrix ===
  a  b  c  d   <-- classified as
 19  0  0  0 |  a
  0 24  0  0 |  b
  0  0 25  0 |  c
  0  0  0 19 |  d
\end{lstlisting}

\noindent Bayes Net:
\begin{lstlisting}
Time taken to build model: 0.01 seconds
=== Evaluation on training set ===
=== Summary ===
Correctly Classified Instances          86               98.8506 %
Incorrectly Classified Instances         1                1.1494 %
Total Number of Instances               87     
=== Confusion Matrix ===
  a  b  c  d   <-- classified as
 19  0  0  0 |  a
  0 24  0  0 |  b
  0  0 24  1 |  c
  0  0  0 19 |  d
\end{lstlisting}
The results show that the Naive Bayes algorithm classified all instances correctly whereas Bayes Net had one error when using the learning set as the test set.

A major difference in performance can be seen when separating the learning set from the training set. As it can be seen below, Bayes Networks perform much better in classifying the data, with only three errors.

\noindent Naive Bayes:
\begin{lstlisting}
Time taken to build model: 0 seconds
=== Evaluation on test set ===
=== Summary ===
Correctly Classified Instances          37               84.0909 %
Incorrectly Classified Instances         7               15.9091 %
Total Number of Instances               44     
=== Confusion Matrix ===
  a  b  c  d   <-- classified as
  9  0  0  0 |  a
  0 13  0  0 |  b
  0  0 13  2 |  c
  5  0  0  2 |  d
\end{lstlisting}

\noindent Naive Bayes:
\begin{lstlisting}
=== Evaluation on test set ===
=== Summary ===
Correctly Classified Instances          41               93.1818 %
Incorrectly Classified Instances         3                6.8182 %
Total Number of Instances               44     
=== Confusion Matrix ===
  a  b  c  d   <-- classified as
  8  1  0  0 |  a
  0 13  0  0 |  b
  0  0 13  2 |  c
  0  0  0  7 |  d


\end{lstlisting}

A worst case scenario test was taken, with only two instances for each room in the training set and 79 instances in the test set. The results show that, even with such a scarce learning set and large test set, Naive Bayes classified 60.7\% of instances correctly and, using Bayes Networks, 70.8\% of instances were correctly classified. It is important to mention that this worst case scenario is highly improbable.

In the strand campus case, three rooms were tested and 40 readings were taken in total: 8 readings for room a, 22 for room b and 10 for room c. Below are the results of applying the model on the learning set.

\noindent Naive Bayes:
\begin{lstlisting}
Time taken to build model: 0.02 seconds
=== Evaluation on training set ===
=== Summary ===
Correctly Classified Instances          40              100      %
Incorrectly Classified Instances         0                0      %
Total Number of Instances               40     
=== Confusion Matrix ===
  a  b  c   <-- classified as
  8  0  0 |  a
  0 22  0 |  b
  0  0 10 |  c
\end{lstlisting}

\noindent Bayes Net:
\begin{lstlisting}
Time taken to build model: 0.06 seconds
=== Evaluation on training set ===
=== Summary ===
Correctly Classified Instances          40              100      %
Incorrectly Classified Instances         0                0      %
Total Number of Instances               40     
=== Confusion Matrix ===
  a  b  c   <-- classified as
  8  0  0 |  a
  0 22  0 |  b
  0  0 10 |  c
\end{lstlisting}
As it can be seen, 100\% of instances were correctly classified using both classifiers, with a difference of 0.04 seconds in performance. 

In the second test, only 17 instances were used for learning and 23 instances were used for testing, the results being again 100\% for both types of classifiers. Because of such a high precision, the learning set was further reduced to 6 instances (2 for each room) and  the test set was increased to 34 instances. The result was again 100\% for both types of classifiers.

The table below shows the results of other classifiers tested:

\begin{tabular}{ |p{3cm}|p{3cm}|p{3cm}|p{2cm}|p{2cm}| }
 \hline
 \multicolumn{5}{|c|}{Classifier Precision} \\
 \hline
 Classifier Type & Learning Set & Testing Set & Build time & Precision\\
 \hline
 Naive Bayes & 87 Instances & = Learning Set & 0s & 100\% \\
 Bayes Net   & 87 Instances & = Learning Set & 0.01s & 98.75\% \\
 KStar       & 87 Instances & = Learning Set & 0s & 100\% \\
 Decorate    & 87 Instances & = Learning Set & 0.7s & 100\% \\
 NB Trees    & 87 Instances & = Learning Set & 2.54 s & 100\% \\
 Naive Bayes & 42 Instances & 45 Instances   & 0s & 86.66\% \\
 Bayes Net   & 42 Instances & 45 Instances   & 0s & 93.33\% \\
 KStar       & 42 Instances & 45 Instances   & 0s & 60\% \\
 Decorate    & 42 Instances & 45 Instances   & 0.15s & 84.44\% \\
 NB Trees    & 42 Instances & 45 Instances   & 0.01 s & 93.33\% \\
 Naive Bayes & 8 Instances  & 78 Instances   & 0s & 60.75\% \\
 Bayes Net   & 8 Instances  & 78 Instances   & 0s & 70.88\% \\
 KStar       & 8 Instances  & 78 Instances   & 0s & 40.50\% \\
 Decorate    & 8 Instances  & 78 Instances   & 0.01s & 51.89\% \\
 NB Trees    & 8 Instances  & 78 Instances   & 0.01s & 72.15\% \\
 \hline
\end{tabular}

\medskip \noindent Even though NBTrees show a higher precision when a scarce learning set is provided, the build time is quite high when a larger one is used. For 87 instances, a 2.54 second delay will affect the performance of the overall application. The delay would increase even higher if a larger learning set would be given. Therefore, the best solution, given the tests made, is Bayes Net and thus this classifier should be used for the application.
It can also be seen that the precision of this system is higher than that shown by the system in Chapter 2. There, the best result was given by WKNN regression algorithm with 94.16\%, which is comparable to the Bayes Net results when using only 42 instances. We can therefore assume that, given a larger learning set, such as the one provided in the system mentioned in Chapter 2, the results of using Bayes Net can be equal or even better.


\section{Project Evaluation}
All subsystems defined in the specifications were created. For user interaction, two separate Android Applications were developed, one for Administration and one for the Visitors. The Backend and database were developed in NodeJS and serve HTTP Requests through a RESTful API. The positioning system implements Machine Learning and Planning algorithms for identifying the location of the users and for suggesting an efficient visit route.

\subsection{Host and Visitor applications}
Most requirements were met for both the Host and Visitor Android applications. 

The HOST can create, delete and view buildings and rooms. The ability to edit was implemented in the Backend, but not in the applications. This is because the quality of the interface was not a main concern when developing the project and editing would have made the interface even more crowded than it already is, without offering such an important capability, given that the building layouts do not change that often. (H1, H2)

As mentioned above, the application can scan and send to the server all Signal Strength Measurements taken in a scan (H3). When a room is being measured, scans are done one after the other, with the shortest possible delay. One issue here is that, the Android SDK does not allow for "explicit" calls to scan. The function call serves as a request to the system, which will handle the scan when available. The time between scans cannot be further reduced, therefore it can be considered a small limitation. Updating the positioning system was implemented (H4), however resetting was not. A reset of the system can be made by deleting the ARFF file stored on the server. This was because the feature did not prove useful enough to be accessible through the app. It could even create more problems if a reset command is called by mistake. 

The Visitor can view a list of buildings and select a specific building from the list (V1). Suggesting the building in which the user is located was not implemented (V2). This was due to the complexity that the implementation would have added to the system. Because the system is only in its early stages, not enough buildings would be stored for this requirement, and the complexity that it adds, to be justified. The visitor can choose the rooms to visit, rating their importance (V3, V5). An estimated time of the visit and a planned route based on the previously mentioned requirements are suggested to the user (V4, V6). The Visitor's current location is also displayed and updated (V7). One limitation here is again, as mentioned above, the delay between scans. Requirements (V8) was not implemented, showing only the path from the beginning to the end, not updating it based on the user location. This was done because, if the user does leave the suggested path, it is likely that they would be able to find their way back on the suggested path, especially knowing their location. Not implementing V8 increased the performance and decreased unnecessary complexity of the system.

\subsection{Positioning system}
The positioning system has implemented both the positioning and planning algorithms. 

The Machine Learning algorithm was implemented using the Weka library ~\cite{Weka}. It can parse the data received from the backend, creating classifiers or classifying the data received (PS1, PS2, PS3, PS4, PS5). The model takes less than 10 seconds to build and has a higher than 80\% precision rate. Thus both performance requirements were met.

The Positioning Server receives the specifications given by the visitor for a route, planning the route using OPTIC Planner (PS6, PS7). The planning was limited to 1 second, which is 1 second below the maximum value in the Specifications.

\subsection{Backend}
All the models specified were implemented and can be stored in the MongoDB database implemented(B1, B2). A RESTful API was implemented, handling requests received for retrieving data from the database or from the positioning system (B3).     




 
